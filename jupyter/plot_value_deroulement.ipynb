{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b25b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hydra\n",
    "from hydra.utils import to_absolute_path\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import dgl\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "#project_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', ''))\n",
    "#sys.path.append(project_path)\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), '..', ''))\n",
    "sys.path.append(project_path)\n",
    "\n",
    "from python.create_dgl_dataset import TelemacDataset\n",
    "from modulus.distributed.manager import DistributedManager\n",
    "from modulus.launch.logging import (\n",
    "    PythonLogger,\n",
    "    RankZeroLoggingWrapper,\n",
    "    initialize_wandb,\n",
    ")\n",
    "from modulus.launch.utils import load_checkpoint, save_checkpoint\n",
    "from python.CustomMeshGraphNet import MeshGraphNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f33413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import to_absolute_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889d2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c46381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch is a list of sequences\n",
    "    # Each sequence is a list of graphs (of length sequence_length)\n",
    "    # We want to batch the graphs at each time step across sequences\n",
    "\n",
    "    sequence_length = len(batch[0])  # Assuming all sequences have the same length\n",
    "\n",
    "    batched_graphs = []\n",
    "    for t in range(sequence_length):\n",
    "        graphs_at_t = [sequence[t] for sequence in batch]\n",
    "        batched_graph = dgl.batch(graphs_at_t)\n",
    "        batched_graphs.append(batched_graph)\n",
    "\n",
    "    return batched_graphs\n",
    "\n",
    "class TestRollout:\n",
    "    def __init__(self, cfg: DictConfig, logger: PythonLogger):\n",
    "        self.sequence_length = cfg.sequence_length  # Use sequence_length from config\n",
    "        \n",
    "        # Set device\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        logger.info(f\"Using {self.device} device\")\n",
    "        \n",
    "        # Instantiate dataset\n",
    "        self.dataset = TelemacDataset(\n",
    "            name=\"telemac_test\",\n",
    "            data_dir=to_absolute_path(cfg.data_dir),\n",
    "            dynamic_data_files=[to_absolute_path(path) for path in cfg.dynamic_dir],\n",
    "            split=\"test\",\n",
    "            ckpt_path=cfg.ckpt_path,\n",
    "            normalize=True,\n",
    "            sequence_length=self.sequence_length,\n",
    "        )\n",
    "        \n",
    "        # Instantiate dataloader\n",
    "        self.dataloader = GraphDataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=1,  \n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=collate_fn,  # Use custom collate_fn if defined\n",
    "        )\n",
    "        print(f\"DataLoader Length: {len(self.dataloader)}\")\n",
    "\n",
    "        # Instantiate the model\n",
    "        self.model = MeshGraphNet(\n",
    "            cfg.num_input_features,\n",
    "            cfg.num_edge_features,\n",
    "            cfg.num_output_features,\n",
    "            processor_size=cfg.mp_layers,\n",
    "            hidden_dim_processor=64,\n",
    "            hidden_dim_node_encoder=64,\n",
    "            hidden_dim_edge_encoder=64,\n",
    "            hidden_dim_node_decoder=64,\n",
    "            do_concat_trick=cfg.do_concat_trick,\n",
    "            num_processor_checkpoint_segments=cfg.num_processor_checkpoint_segments,\n",
    "        )\n",
    "        if cfg.jit:\n",
    "            self.model = torch.jit.script(self.model).to(self.device)\n",
    "        else:\n",
    "            self.model = self.model.to(self.device)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Load checkpoint\n",
    "        load_checkpoint(\n",
    "            to_absolute_path(cfg.ckpt_path),\n",
    "            models=self.model,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Get the stats needed to denormalize and normalize\n",
    "        node_stats = self.dataset.node_stats\n",
    "        self.h_u_v_i_0_mean = np.array([\n",
    "            node_stats['h'].item(),\n",
    "            node_stats['u'].item(),\n",
    "            node_stats['v'].item()\n",
    "        ])\n",
    "        self.h_u_v_i_0_std = np.array([\n",
    "            node_stats['h_std'].item(),\n",
    "            node_stats['u_std'].item(),\n",
    "            node_stats['v_std'].item()\n",
    "        ])\n",
    "\n",
    "        self.delta_h_u_v_i_diff_mean = np.array([\n",
    "            node_stats['delta_h'].item(),\n",
    "            node_stats['delta_u'].item(),\n",
    "            node_stats['delta_v'].item()\n",
    "        ])\n",
    "        self.delta_h_u_v_i_diff_std = np.array([\n",
    "            node_stats['delta_h_std'].item(),\n",
    "            node_stats['delta_u_std'].item(),\n",
    "            node_stats['delta_v_std'].item()\n",
    "        ])\n",
    "        \n",
    "        # Define feature indices\n",
    "        self.dynamic_feature_start = 6  # Adjust based on your actual feature indices\n",
    "        self.dynamic_feature_end = 9  # Adjust based on your actual feature indices\n",
    "        \n",
    "    def predict(self, graph):\n",
    "        \"\"\"\n",
    "        Predicts the next time step given the input graph.\n",
    "        Denormalizes input features and predictions.\n",
    "        Returns the denormalized predicted values.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(\n",
    "                graph.ndata['x'].to(self.device),\n",
    "                graph.edata['x'].to(self.device),\n",
    "                graph.to(self.device)\n",
    "            ).cpu().numpy()\n",
    "        \n",
    "        # Denormalize data\n",
    "        h_u_v_i_0 = self._denormalize_data(\n",
    "            graph.ndata['x'][:, self.dynamic_feature_start:self.dynamic_feature_end].numpy(),\n",
    "            self.h_u_v_i_0_mean,\n",
    "            self.h_u_v_i_0_std\n",
    "        )\n",
    "\n",
    "        # Compute predicted h, u, v at next time step\n",
    "        h_u_v_i_1_pred = self._denormalize_data(\n",
    "            pred,\n",
    "            self.delta_h_u_v_i_diff_mean,\n",
    "            self.delta_h_u_v_i_diff_std\n",
    "        ) + h_u_v_i_0\n",
    "                \n",
    "        return h_u_v_i_1_pred, h_u_v_i_0\n",
    "        \n",
    "    def maj_mask(self, pred, next_step):\n",
    "        \"\"\"\n",
    "        Updates predictions by applying boundary conditions from the next step.\n",
    "        pred and next_step are normalized.\n",
    "        \"\"\"\n",
    "        next_step_np = next_step.numpy()\n",
    "        # Identify nodes with specific boundary conditions\n",
    "        self.q_mask = (next_step_np[:, 0:4] == [0, 0, 1, 0]).all(axis=1)\n",
    "        self.h_mask = (next_step_np[:, 0:4] == [0, 1, 0, 0]).all(axis=1)\n",
    "        result = np.empty_like(next_step_np)\n",
    "        \n",
    "        # Copy static features from next_step\n",
    "        result[:, 0:6] = next_step_np[:, 0:6]\n",
    "        \n",
    "        # Use predictions for dynamic features\n",
    "        result[:, 6:9] = pred\n",
    "        \n",
    "        # Apply boundary conditions\n",
    "        result[self.q_mask, 6:9] = next_step_np[self.q_mask, 6:9]\n",
    "        result[self.h_mask, 6:7] = next_step_np[self.h_mask, 6:7]\n",
    "        return result \n",
    "    \n",
    "    def predict_unroll(self, unroll_start,unroll_steps=1):\n",
    "        predict = []\n",
    "        groundtruth = []\n",
    "        origin = []\n",
    "        sequence = self.dataloader:\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length < unroll_steps + 1:\n",
    "            continue  # Skip sequences that are too short\n",
    "\n",
    "        graph = sequence[0].clone()  # Start from the first graph in the sequence\n",
    "        h_u_v_i_0 = None  # To store initial input at time t=0\n",
    "        for i in range(unroll_steps):\n",
    "            next_graph = sequence[i + 1]\n",
    "            h_u_v_i_1_pred, h_u_v_i_0 = self.predict(graph)\n",
    "\n",
    "            if i == 0:\n",
    "                origin.append(h_u_v_i_0)\n",
    "\n",
    "            noise_filter = h_u_v_i_1_pred[:, 0] < 5e-3\n",
    "            h_u_v_i_1_pred[noise_filter, :] = 0.0\n",
    "\n",
    "            # Normalize the prediction to transfer to the next graph\n",
    "            h_u_v_i_1_pred_norm = self._normalize_data(\n",
    "                    h_u_v_i_1_pred,\n",
    "                    self.h_u_v_i_0_mean,\n",
    "                    self.h_u_v_i_0_std\n",
    "                )\n",
    "\n",
    "            # Apply boundary conditions\n",
    "            next_step_result = self.maj_mask(\n",
    "                    h_u_v_i_1_pred_norm,\n",
    "                    next_graph.ndata['x']\n",
    "                )\n",
    "\n",
    "            # Update the graph's node features for the next prediction\n",
    "            graph.ndata['x'] = torch.tensor(next_step_result, dtype=torch.float32)\n",
    "\n",
    "            predict.append(h_u_v_i_1_pred)\n",
    "            # Denormalize ground truth from next_graph\n",
    "            groundtruth.append(self._denormalize_data(\n",
    "                next_graph.ndata['x'][:, self.dynamic_feature_start:self.dynamic_feature_end].numpy(),\n",
    "                self.h_u_v_i_0_mean,\n",
    "                self.h_u_v_i_0_std\n",
    "            ))\n",
    "\n",
    "        return predict, groundtruth, origin\n",
    "\n",
    "    def _denormalize_data(self, tensor, mean, std):\n",
    "        assert tensor.shape[1] == mean.shape[0]\n",
    "        return tensor * std + mean \n",
    "    \n",
    "    def _normalize_data(self, tensor, mean, std):\n",
    "        assert tensor.shape[1] == mean.shape[0]\n",
    "        return (tensor - mean) / std\n",
    "    \n",
    "    def get_raw_data(self, idx):\n",
    "        self.pred_i = [var[:, idx] for var in self.pred]\n",
    "        self.exact_i = [var[:, idx] for var in self.exact]\n",
    "        return self.graphs, self.faces, self.pred_i, self.exact_i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680e52c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3965000/3700403011.py:8: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"../bin/conf\"):\n",
      "[13:30:06 - main - INFO] \u001b[94mUsing cuda device\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir: /work/m24046/m24046mrcr/results_data_30min/Multimesh_2_32_True.bin\n",
      "dynamic_dir:\n",
      "- /work/m24046/m24046mrcr/results_data_30min/Group_2_peak_2600_Group_2_peak_2600_0_0-80.pkl\n",
      "batch_size: 1\n",
      "epochs: 1500\n",
      "mp_layers: 12\n",
      "lr: 0.0005\n",
      "lr_decay_rate: 0.999995\n",
      "num_input_features: 9\n",
      "num_output_features: 3\n",
      "num_edge_features: 3\n",
      "custom_loss: false\n",
      "sequence_length: 21\n",
      "use_apex: true\n",
      "amp: false\n",
      "jit: false\n",
      "num_dataloader_workers: 1\n",
      "do_concat_trick: true\n",
      "num_processor_checkpoint_segments: 0\n",
      "recompute_activation: false\n",
      "loading_path: /work/m24046/m24046mrcr/full_dataset_30_tt\n",
      "ckpt_path: /work/m24046/m24046mrcr/full_dataset_30_tt\n",
      "\n",
      "Loading normalization statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:30:07 - checkpoint - INFO] \u001b[92mLoaded model state dictionary /work/m24046/m24046mrcr/full_dataset_30_tt/MeshGraphNet.0.490.mdlus to device cuda\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader Length: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:30:07 - checkpoint - INFO] \u001b[92mLoaded checkpoint file /work/m24046/m24046mrcr/full_dataset_30_tt/checkpoint.0.490.pt to device cuda\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per unroll 8.622853914896647\n",
      "1729769407.642043\n",
      "1729769433.5106049\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import time \n",
    "\n",
    "# Initialize Hydra and set the configuration directory\n",
    "with initialize(config_path=\"../bin/conf\"):\n",
    "    logger = PythonLogger(\"main\")  # General python logger\n",
    "    logger.file_logging()\n",
    "    # Compose the configuration using the config name\n",
    "    cfg = compose(config_name=\"config_30min_througthtime_test\")\n",
    "    \n",
    "    # Display the configuration (optional)\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    # Now call the training function with the composed config\n",
    "    test = TestRollout(cfg,logger)\n",
    "    \n",
    "    predict,groundtruth,origin = test.predict_unroll(unroll_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08e649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
